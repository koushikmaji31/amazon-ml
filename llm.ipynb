{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import pytesseract\n",
    "import requests\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path\n",
    "image_path = \"train_images/619cPZMqL7L.jpg\"\n",
    "\n",
    "# Open and resize the image\n",
    "image = PILImage.open(image_path).convert('RGB')\n",
    "fixed_size = (400, 400)  # Set the desired size (width, height)\n",
    "resized_image = image.resize(fixed_size)\n",
    "\n",
    "# Save the resized image to a temporary file\n",
    "resized_image_path = '/tmp/resized_image.jpg'\n",
    "resized_image.save(resized_image_path)\n",
    "\n",
    "# Display the resized image with fixed size in a notebook\n",
    "display(Image(filename=resized_image_path, width=400, height=400))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True, torch_dtype=torch.float16)\n",
    "model = model.to(device='cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True)\n",
    "from PIL import Image\n",
    "\n",
    "# Load and convert the image\n",
    "image = Image.open('train_images/116R4t6IioL.jpg').convert('RGB')\n",
    "\n",
    "extracted_text = \"ENERGY Zhongshal Fauhuo lighting Co, Ltd. FS—A1 —30W 30 kWH/1000h \"\n",
    "prompt = \"Identify the wattage from the text and image and output only two words, The unit should be one of 'kilowatt' or 'watt'.\"\n",
    "input_text = f\"Extracted text: {extracted_text}\\nPrompt: {prompt}\"\n",
    "\n",
    "msgs = [{'role': 'user', 'content': input_text}]\n",
    "\n",
    "# Generate response\n",
    "res = model.chat(\n",
    "    image=image,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Collect the generated response\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end='')\n",
    "\n",
    "# Print the final result\n",
    "print(\"Final output:\", generated_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model size\n",
    "import os\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    return total_size\n",
    "\n",
    "model_dir = os.path.expanduser('~/.cache/huggingface/hub/models--openbmb--MiniCPM-Llama3-V-2_5')\n",
    "size_bytes = get_directory_size(model_dir)\n",
    "size_mb = size_bytes / (1024 * 1024)\n",
    "print(f\"Size of the model directory: {size_mb:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
