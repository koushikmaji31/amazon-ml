{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 51*70 IN 31 0Z warm soft and ventilate Particularly smooth Comfortable to skin GARDEN\n",
      "Converted: 51*70 inch 31 ounce warm soft and ventilate Particularly smooth Comfortable to skin GARDEN\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# List of possible units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Flattened set of all units from the entity_unit_map\n",
    "all_units = {unit for units in entity_unit_map.values() for unit in units}\n",
    "# Extend unit mapping with more abbreviations like \"IN\" to \"inch\" and \"0Z\" to \"ounce\"\n",
    "unit_mapping = {\n",
    "    'g': 'gram',\n",
    "    'kg': 'kilogram',\n",
    "    'mg': 'milligram',\n",
    "    'mcg': 'microgram',\n",
    "    'oz': 'ounce',\n",
    "    '0z': 'ounce',  # Handle \"0Z\" case\n",
    "    'lb': 'pound',\n",
    "    't': 'ton',\n",
    "    'ml': 'millilitre',\n",
    "    'l': 'litre',\n",
    "    'cl': 'centilitre',\n",
    "    'dl': 'decilitre',\n",
    "    'fl oz': 'fluid ounce',\n",
    "    'ft': 'foot',\n",
    "    'in': 'inch',  # Handle \"IN\" case\n",
    "    'cm': 'centimetre',\n",
    "    'mm': 'millimetre',\n",
    "    'yd': 'yard',\n",
    "    'v': 'volt',\n",
    "    'mv': 'millivolt',\n",
    "    'kv': 'kilovolt',\n",
    "    'w': 'watt',\n",
    "    'kw': 'kilowatt',\n",
    "    'gal': 'gallon',\n",
    "    'pt': 'pint',\n",
    "    'qt': 'quart',\n",
    "    'cu ft': 'cubic foot',\n",
    "    'cu in': 'cubic inch',\n",
    "    'imp gal': 'imperial gallon'\n",
    "}\n",
    "\n",
    "def normalize_unit(unit):\n",
    "    # Normalize the input unit to match the standard list\n",
    "    unit = unit.lower().strip()\n",
    "\n",
    "    # Handle plural units by removing 's' and checking if the singular form exists\n",
    "    if unit.endswith('s') and unit[:-1] in all_units:\n",
    "        unit = unit[:-1]\n",
    "\n",
    "    if unit in unit_mapping:\n",
    "        return unit_mapping[unit]\n",
    "\n",
    "    return unit\n",
    "\n",
    "def extract_value_unit(input_string):\n",
    "    # Regular expression to extract numeric value and unit\n",
    "    pattern = r\"(\\d+\\.?\\d*)\\s*([a-zA-Z]+(?:\\s*[a-zA-Z]*)?)\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "\n",
    "    # Return the first valid match\n",
    "    for match in matches:\n",
    "        value = match[0]  # Extract numeric value\n",
    "        unit = normalize_unit(match[1])  # Extract and normalize unit\n",
    "\n",
    "        if unit in all_units:  # Check if unit is in the list of allowed units\n",
    "            return f\"{value} {unit}\"\n",
    "    \n",
    "    return None  # If no valid match is found\n",
    "\n",
    "def convert_units_in_context(context_string):\n",
    " \n",
    "    # Split the context string into words\n",
    "    words = context_string.split()\n",
    "\n",
    "    # Convert each word if it's a unit abbreviation\n",
    "    converted_words = []\n",
    "    for word in words:\n",
    "        # Check if the word matches any of the unit mappings\n",
    "        lower_word = word.lower()  # For case-insensitive matching\n",
    "        if lower_word in unit_mapping:\n",
    "            converted_words.append(unit_mapping[lower_word])\n",
    "        else:\n",
    "            converted_words.append(word)\n",
    "\n",
    "    # Join the words back into a context string\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "# Example context from JSON\n",
    "context = \"51*70 IN 31 0Z warm soft and ventilate Particularly smooth Comfortable to skin GARDEN\"\n",
    "\n",
    "# Convert the context units\n",
    "converted_context = convert_units_in_context(context)\n",
    "\n",
    "print(f\"Original: {context}\")\n",
    "print(f\"Converted: {converted_context}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        easyocr_text  \\\n",
      "0  PROPOS' NATURE INGREDIENT MENAGER MULTI-USAGE ...   \n",
      "1  TLaeel=_ 7672 Xe RRIFIC LEBENSMITTELECHT Gw DA...   \n",
      "2                                                NaN   \n",
      "3  3 3 1 1 F IW! 1 5833 1 3 1 1 1 1 H 0 L 1 W # I...   \n",
      "4  Horbaach' HIGH StRENGTH PSYLLIUM HUSK PLANTAGO...   \n",
      "\n",
      "                                      tesseract_text    entity_value  \\\n",
      "0                                                NaN      500.0 gram   \n",
      "1  GEPRAGTES  par Sitaram]  a UND GESCHUTZTE DESIGNS         1.0 cup   \n",
      "2  Serving Size: 1 Tablet (0.709 g) | Each servin...      0.709 gram   \n",
      "3                                                NaN      0.709 gram   \n",
      "4                         Sos ai ace  PSYLLIUM  HUSK  1400 milligram   \n",
      "\n",
      "   answer_start_easyocr  answer_start_tesseract  \n",
      "0                    -1                      -1  \n",
      "1                    -1                      -1  \n",
      "2                    -1                      -1  \n",
      "3                    -1                      -1  \n",
      "4                    -1                      -1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('dataset/final_train.csv')\n",
    "\n",
    "# List of possible units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Flattened set of all units from the entity_unit_map\n",
    "all_units = {unit for units in entity_unit_map.values() for unit in units}\n",
    "\n",
    "# Extend unit mapping with more abbreviations\n",
    "unit_mapping = {\n",
    "    'g': 'gram',\n",
    "    'kg': 'kilogram',\n",
    "    'mg': 'milligram',\n",
    "    'mcg': 'microgram',\n",
    "    'oz': 'ounce',\n",
    "    '0z': 'ounce',  # Handle \"0Z\" case\n",
    "    'lb': 'pound',\n",
    "    't': 'ton',\n",
    "    'ml': 'millilitre',\n",
    "    'l': 'litre',\n",
    "    'cl': 'centilitre',\n",
    "    'dl': 'decilitre',\n",
    "    'fl oz': 'fluid ounce',\n",
    "    'ft': 'foot',\n",
    "    'in': 'inch',  # Handle \"IN\" case\n",
    "    'cm': 'centimetre',\n",
    "    'mm': 'millimetre',\n",
    "    'yd': 'yard',\n",
    "    'v': 'volt',\n",
    "    'mv': 'millivolt',\n",
    "    'kv': 'kilovolt',\n",
    "    'w': 'watt',\n",
    "    'kw': 'kilowatt',\n",
    "    'gal': 'gallon',\n",
    "    'pt': 'pint',\n",
    "    'qt': 'quart',\n",
    "    'cu ft': 'cubic foot',\n",
    "    'cu in': 'cubic inch',\n",
    "    'imp gal': 'imperial gallon'\n",
    "}\n",
    "\n",
    "def normalize_unit(unit):\n",
    "    unit = unit.lower().strip()\n",
    "    if unit.endswith('s') and unit[:-1] in all_units:\n",
    "        unit = unit[:-1]\n",
    "    return unit_mapping.get(unit, unit)\n",
    "\n",
    "def convert_units_in_context(context_string):\n",
    "    words = context_string.split()\n",
    "    converted_words = [unit_mapping.get(word.lower(), word) for word in words]\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "## Function to ensure the text is a string and handle NaN values\n",
    "def safe_str(value):\n",
    "    return str(value) if pd.notnull(value) else \"\"\n",
    "\n",
    "# Function to extract the number or values before the first space\n",
    "def extract_number(entity_value):\n",
    "    match = re.match(r'^\\S+', entity_value)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return entity_value\n",
    "\n",
    "# Function to find the answer_start indices in both easyocr_text and tesseract_text\n",
    "def find_answer_indices(row):\n",
    "    # Apply unit conversion on the text\n",
    "    easyocr_text = convert_units_in_context(safe_str(row['easyocr_text']))\n",
    "    tesseract_text = convert_units_in_context(safe_str(row['tesseract_text']))\n",
    "\n",
    "    # Concatenate the easyocr_text and tesseract_text as a single context string\n",
    "    concatenated_text = easyocr_text + \" \" + tesseract_text\n",
    "    \n",
    "    # Extract the number from entity_value\n",
    "    entity_value_number = extract_number(row['entity_value'])\n",
    "    \n",
    "    # Find the number in both easyocr_text and tesseract_text\n",
    "    index_easyocr = easyocr_text.find(entity_value_number)\n",
    "    index_tesseract = tesseract_text.find(entity_value_number)\n",
    "    \n",
    "    # If found in both texts, return the answer start indices for both\n",
    "    if index_easyocr != -1 and index_tesseract != -1:\n",
    "        return index_easyocr, len(easyocr_text) + 1 + index_tesseract\n",
    "    else:\n",
    "        return -1, -1\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "df['answer_start_easyocr'], df['answer_start_tesseract'] = zip(*df.apply(find_answer_indices, axis=1))\n",
    "\n",
    "# Show the processed dataframe\n",
    "print(df[['easyocr_text', 'tesseract_text', 'entity_value', 'answer_start_easyocr', 'answer_start_tesseract']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         easyocr_text  \\\n",
      "0   PROPOS' NATURE INGREDIENT MENAGER MULTI-USAGE ...   \n",
      "1   TLaeel=_ 7672 Xe RRIFIC LEBENSMITTELECHT Gw DA...   \n",
      "2                                                 NaN   \n",
      "3   3 3 1 1 F IW! 1 5833 1 3 1 1 1 1 H 0 L 1 W # I...   \n",
      "4   Horbaach' HIGH StRENGTH PSYLLIUM HUSK PLANTAGO...   \n",
      "..                                                ...   \n",
      "95                                                NaN   \n",
      "96                                                NaN   \n",
      "97  Herbal max BENEFITS OF GREEN COFFEE Discov er ...   \n",
      "98  166 Thick High Grade 304 Stainless Steel Anti-...   \n",
      "99  NEW OOs FooD ONLT # NEW RPURINAP @ SUPERCOAT '...   \n",
      "\n",
      "                                       tesseract_text    entity_value  \\\n",
      "0                                                 NaN      500.0 gram   \n",
      "1   GEPRAGTES  par Sitaram]  a UND GESCHUTZTE DESIGNS         1.0 cup   \n",
      "2   Serving Size: 1 Tablet (0.709 g) | Each servin...      0.709 gram   \n",
      "3                                                 NaN      0.709 gram   \n",
      "4                          Sos ai ace  PSYLLIUM  HUSK  1400 milligram   \n",
      "..                                                ...             ...   \n",
      "95                                                NaN       49.0 watt   \n",
      "96                                                NaN   500 milligram   \n",
      "97  lee.  *YHerbal max  iscover weliness  GREEN CO...   500 milligram   \n",
      "98                                                NaN       16.0 gram   \n",
      "99                     1 AU SONr.N  | » Ata PAU AAR a      8 kilogram   \n",
      "\n",
      "    answer_start_easyocr  answer_start_tesseract  \n",
      "0                    431                      -1  \n",
      "1                     -1                      -1  \n",
      "2                     -1                      25  \n",
      "3                     -1                      -1  \n",
      "4                     53                      -1  \n",
      "..                   ...                     ...  \n",
      "95                    -1                      -1  \n",
      "96                    -1                      -1  \n",
      "97                    -1                     690  \n",
      "98                     0                      -1  \n",
      "99                    -1                      -1  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract the number or values before space\n",
    "def extract_number(entity_value):\n",
    "    # Use regex to extract the part before the first space\n",
    "    match = re.match(r'^\\S+', entity_value)  # Extract the numeric part before space\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return entity_value  # Return original if no match\n",
    "\n",
    "## Function to ensure the text is a string and handle NaN values\n",
    "def safe_str(value):\n",
    "    return str(value) if pd.notnull(value) else \"\"\n",
    "\n",
    "# Function to clean text by removing symbols and spaces (only retain numbers)\n",
    "def clean_text(text):\n",
    "    # Remove all symbols except numbers\n",
    "    return re.sub(r'[^\\d]', '', text)  # Keep only digits, remove everything else\n",
    "\n",
    "# Function to remove decimal point from entity_value\n",
    "def clean_entity_value(entity_value):\n",
    "    return entity_value.replace('.', '')  # Remove decimal point\n",
    "\n",
    "# Function to find answer indices in original text, with fallback to cleaned text\n",
    "def find_answer_indices(row):\n",
    "    original_easyocr_text = safe_str(row['easyocr_text'])\n",
    "    original_tesseract_text = safe_str(row['tesseract_text'])\n",
    "    \n",
    "    # Extract the number from entity_value\n",
    "    entity_value_number = extract_number(row['entity_value'])\n",
    "    \n",
    "    # First search: find number in original text\n",
    "    index_easyocr = original_easyocr_text.find(entity_value_number)\n",
    "    index_tesseract = original_tesseract_text.find(entity_value_number)\n",
    "    \n",
    "    # If found in both, return the indices\n",
    "    if index_easyocr != -1 and index_tesseract != -1:\n",
    "        return index_easyocr, len(original_easyocr_text) + 1 + index_tesseract\n",
    "    \n",
    "    # Second attempt: Clean text and entity_value\n",
    "    cleaned_easyocr_text = clean_text(original_easyocr_text)\n",
    "    cleaned_tesseract_text = clean_text(original_tesseract_text)\n",
    "    cleaned_entity_value_number = clean_entity_value(entity_value_number)\n",
    "        \n",
    "    # Search again in cleaned text\n",
    "    cleaned_index_easyocr = cleaned_easyocr_text.find(cleaned_entity_value_number)\n",
    "    cleaned_index_tesseract = cleaned_tesseract_text.find(cleaned_entity_value_number)\n",
    "    \n",
    "    # If found in cleaned text, map the indices back to original text\n",
    "    if cleaned_index_easyocr != -1 and cleaned_index_tesseract != -1:\n",
    "        index_easyocr = map_cleaned_to_original(cleaned_easyocr_text, original_easyocr_text, cleaned_index_easyocr)\n",
    "        index_tesseract = map_cleaned_to_original(cleaned_tesseract_text, original_tesseract_text, cleaned_index_tesseract)\n",
    "        return index_easyocr, len(original_easyocr_text) + 1 + index_tesseract\n",
    "    elif cleaned_index_easyocr != -1: \n",
    "        index_easyocr = map_cleaned_to_original(cleaned_easyocr_text, original_easyocr_text, cleaned_index_easyocr)\n",
    "        # return index_easyocr, -1\n",
    "    elif cleaned_index_tesseract != -1:\n",
    "        index_tesseract = map_cleaned_to_original(cleaned_tesseract_text, original_tesseract_text, cleaned_index_tesseract)\n",
    "        # return -1, len(original_easyocr_text) + 1 + index_tesseract\n",
    "    \n",
    "    cleaned_shortened_entity_value_number = cleaned_entity_value_number[:2]\n",
    "    cleaned_shortened_index_easyocr = cleaned_easyocr_text.find(cleaned_shortened_entity_value_number)\n",
    "    cleaned_shortened_index_tesseract = cleaned_tesseract_text.find(cleaned_shortened_entity_value_number)\n",
    "    \n",
    "    if cleaned_shortened_index_easyocr != -1 and cleaned_shortened_index_tesseract != -1:\n",
    "        index_easyocr = map_cleaned_to_original(cleaned_easyocr_text, original_easyocr_text, cleaned_shortened_index_easyocr)\n",
    "        index_tesseract = map_cleaned_to_original(cleaned_tesseract_text, original_tesseract_text, cleaned_shortened_index_tesseract)\n",
    "        return index_easyocr, len(original_easyocr_text) + 1 + index_tesseract\n",
    "    elif cleaned_shortened_index_easyocr != -1:\n",
    "        index_easyocr = map_cleaned_to_original(cleaned_easyocr_text, original_easyocr_text, cleaned_shortened_index_easyocr)\n",
    "        return index_easyocr, -1\n",
    "    elif cleaned_shortened_index_tesseract != -1:\n",
    "        index_tesseract = map_cleaned_to_original(cleaned_tesseract_text, original_tesseract_text, cleaned_shortened_index_tesseract)\n",
    "        return -1, len(original_easyocr_text) + 1 + index_tesseract\n",
    "    else :\n",
    "        return -1, -1\n",
    "        \n",
    "\n",
    "# Function to map cleaned text index back to original text index\n",
    "def map_cleaned_to_original(cleaned_text, original_text, cleaned_index):\n",
    "    cleaned_so_far = 0\n",
    "    for i, char in enumerate(original_text):\n",
    "        if char.isdigit():  # Only count digits\n",
    "            if cleaned_so_far == cleaned_index:\n",
    "                return i\n",
    "            cleaned_so_far += 1\n",
    "    return -1  # Return -1 if no match\n",
    "\n",
    "# Apply the function to each row\n",
    "df['answer_start_easyocr'], df['answer_start_tesseract'] = zip(*df.apply(find_answer_indices, axis=1))\n",
    "\n",
    "# Show the processed dataframe\n",
    "print(df[['easyocr_text', 'tesseract_text', 'entity_value', 'answer_start_easyocr', 'answer_start_tesseract']].head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer start index in easyocr_text: 0\n",
      "Answer start index in tesseract_text: 11\n"
     ]
    }
   ],
   "source": [
    "test_sample = {\n",
    "    'easyocr_text': \"12345.6 la\",\n",
    "    'tesseract_text': \"1,234.56 kg\",\n",
    "    'entity_value': \"1234.56 kilogram\",\n",
    "    'entity_name': \"weight\"\n",
    "}\n",
    "# Convert the test sample into a pandas Series (like a single row)\n",
    "test_row = pd.Series(test_sample)\n",
    "\n",
    "# Call the function to find answer indices for the single sample\n",
    "answer_start_easyocr, answer_start_tesseract = find_answer_indices(test_row)\n",
    "\n",
    "# Output the results for the single test case\n",
    "print(f\"Answer start index in easyocr_text: {answer_start_easyocr}\")\n",
    "print(f\"Answer start index in tesseract_text: {answer_start_tesseract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_link                263859\n",
      "group_id                  263859\n",
      "entity_name               263859\n",
      "entity_value              263859\n",
      "image_name                263859\n",
      "easyocr_text              105978\n",
      "tesseract_text            124498\n",
      "answer_start_easyocr      263859\n",
      "answer_start_tesseract    263859\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_values = df.count()\n",
    "print(total_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def generate_json_from_dataframe(df):\n",
    "    train_data = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        # Convert NaN values to empty strings\n",
    "        easyocr_text = str(row['easyocr_text']) if pd.notna(row['easyocr_text']) else ''\n",
    "        tesseract_text = str(row['tesseract_text']) if pd.notna(row['tesseract_text']) else ''\n",
    "        \n",
    "        # Concatenate the context from easyocr_text and tesseract_text\n",
    "        context = easyocr_text + ' ' + tesseract_text\n",
    "        \n",
    "        question = f\"What is the value of the {row['entity_name']}?\"\n",
    "        entity_value = row['entity_value']\n",
    "        \n",
    "        # Check if both answer_start_easyocr and answer_start_tesseract are -1\n",
    "        if row['answer_start_easyocr'] == -1 and row['answer_start_tesseract'] == -1:\n",
    "            is_impossible = True\n",
    "            answers = [{\"text\": \"not possible\", \"answer_start\": -1}]\n",
    "        else:\n",
    "            is_impossible = False\n",
    "            # Collect answer starting indexes that are not -1\n",
    "            answer_starts = [row['answer_start_easyocr'], row['answer_start_tesseract']]\n",
    "            answer_starts = [start for start in answer_starts if start != -1]\n",
    "            answers = [{\"text\": entity_value, \"answer_start\": start} for start in answer_starts]\n",
    "        \n",
    "        # Create the Q&A structure\n",
    "        qas = {\n",
    "            \"id\": f\"{idx+1:05}\",\n",
    "            \"is_impossible\": is_impossible,\n",
    "            \"question\": question,\n",
    "            \"answers\": answers if not is_impossible else []\n",
    "        }\n",
    "        \n",
    "        # Append the context and Q&A to the training data\n",
    "        train_data.append({\n",
    "            \"context\": context,\n",
    "            \"qas\": [qas]\n",
    "        })\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Generate the JSON data from the DataFrame\n",
    "json_data = generate_json_from_dataframe(df)\n",
    "\n",
    "# Write to JSON file\n",
    "with open(\"train.json\", \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(json_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON data created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazonml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
